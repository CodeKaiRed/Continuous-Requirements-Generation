{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Requirements Generation with GPT-4\n",
    "This notebook explores the use of utilizing GPT 4 on a domain-specific set of requirements. This model will be used downstream to manage requirements changes provided by external sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pymupdf4llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find next iteration increment for saving the output response\n",
    "import os\n",
    "\n",
    "# change the prefix based on the user story provided to the prompt\n",
    "file_prefix = \"outputs/4-powerpoint-report/iteration-\"\n",
    "file_extension = \".md\"\n",
    "\n",
    "i = 1\n",
    "while os.path.exists(f\"{file_prefix}{i}{file_extension}\"):\n",
    "    i += 1\n",
    "\n",
    "output_filename = f\"{file_prefix}{i}{file_extension}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MODEL_NAME = \"gpt-4o\"\n",
    "IEEE_830 = \"inputs/IEEE 830-1998.pdf\"\n",
    "BRIDGE_INSPECTION = \"inputs/a-state-of-the-art-review-of-bridge-inspection-planning-current-situation-and-future-needs.pdf\"\n",
    "# SRS_PDF_PATH = \"inputs/2005 - pontis.pdf\"\n",
    "# SRS_MD_PATH = \"inputs/output_srs.md\"\n",
    "EDIT_MD_PATH = \"inputs/edited_srs.md\"\n",
    "FINAL_OUTPUT_PATH = output_filename\n",
    "\n",
    "JIRA_ISSUE = \"\"\"\n",
    "As an advanced user, \\\n",
    "I want to export bridge inspection results to a PowerPoint presentation, \\\n",
    "so that I can present risk analysis and recommendations to management personnel in a digestible format.\n",
    "\"\"\"\n",
    "\n",
    "# RAG_DOCUMENTS = [SRS_PDF_PATH, SRS_TXT_PATH, IEEE_830, BRIDGE_INSPECTION]\n",
    "RAG_DOCUMENTS = [EDIT_MD_PATH, IEEE_830, BRIDGE_INSPECTION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the OpenAI api key\n",
    "import json\n",
    "\n",
    "config_data = json.load(open(\"config.json\"))\n",
    "openai_api_key = config_data[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the OpenAI Client\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the system instructions from the prompt file\n",
    "with open(\"prompts/system_instructions.txt\", \"r\") as file:\n",
    "    system_instructions = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Custom Assistant with File Search Capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new assistant with access to the existing system requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Continuous Requirements Generator\",\n",
    "    instructions=system_instructions,\n",
    "    model=MODEL_NAME,\n",
    "    tools=[{\"type\": \"file_search\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the file and add them to a Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=3, failed=0, in_progress=0, total=3)\n"
     ]
    }
   ],
   "source": [
    "# Create a vector store caled \"Financial Statements\"\n",
    "vector_store = client.beta.vector_stores.create(name=\"Gemini Software System Requirements\")\n",
    " \n",
    "# Ready the files for upload to OpenAI\n",
    "file_paths = RAG_DOCUMENTS\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    " \n",
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    " \n",
    "# You can print the status and the file counts of the batch to see the result of this operation.\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the assistand to use the new Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolResourcesFileSearch(vector_store_ids=['vs_oK6iRabkrOLxViX5opp5HlX2'])\n"
     ]
    }
   ],
   "source": [
    "# Upload the user provided file to OpenAI\n",
    "message_file = client.files.create(\n",
    "  file=open(EDIT_MD_PATH, \"rb\"), purpose=\"assistants\"\n",
    ")\n",
    " \n",
    "# Create a thread and attach the file to the message\n",
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": JIRA_ISSUE,\n",
    "      # Attach the new file to the message.\n",
    "      \"attachments\": [\n",
    "        { \"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}] }\n",
    "      ],\n",
    "    }\n",
    "  ]\n",
    ")\n",
    " \n",
    "# The thread now has a vector store with that file in its tool resources.\n",
    "print(thread.tool_resources.file_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a run and check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the user story provided, here's how we can generate the related use cases, functional requirements, and non-functional requirements:\n",
      "\n",
      "### JSON Response\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"use-cases\": [\n",
      "        {\n",
      "            \"parent-section\": \"3.6 DATA MANAGEMENT\",\n",
      "            \"id\": \"UC-17\",\n",
      "            \"modification-type\": \"new\",\n",
      "            \"primary-actor\": \"Advanced user\",\n",
      "            \"scope\": \"Export bridge inspection data\",\n",
      "            \"stakeholders\": \"Inspector, Routine and Advanced User\",\n",
      "            \"precondition\": \"User is logged into Pontis and has the necessary permissions.\",\n",
      "            \"description\": \"The user exports bridge inspection results to a PowerPoint presentation.\",\n",
      "            \"success-end-condition\": \"The bridge inspection results are successfully exported to a PowerPoint presentation.\"\n",
      "        }\n",
      "    ],\n",
      "    \"functional-requirements\": [\n",
      "        {\n",
      "            \"parent-id\": \"UC-17\",\n",
      "            \"id\": \"FR-17.1\",\n",
      "            \"modification-type\": \"new\",\n",
      "            \"description\": \"The system shall provide an option to export bridge inspection results to a PowerPoint presentation format.\"\n",
      "        },\n",
      "        {\n",
      "            \"parent-id\": \"UC-17\",\n",
      "            \"id\": \"FR-17.2\",\n",
      "            \"modification-type\": \"new\",\n",
      "            \"description\": \"The system shall allow the user to include risk analysis and recommendations in the PowerPoint export.\"\n",
      "        },\n",
      "        {\n",
      "            \"parent-id\": \"UC-17\",\n",
      "            \"id\": \"FR-17.3\",\n",
      "            \"modification-type\": \"new\",\n",
      "            \"description\": \"The system shall enable customization of the PowerPoint export including the selection of slides, layout, and formatting options.\"\n",
      "        }\n",
      "    ],\n",
      "    \"non-functional-requirements\": [\n",
      "        {\n",
      "            \"id\": \"USA-1\",\n",
      "            \"modification-type\": \"new\",\n",
      "            \"description\": \"The export feature shall be user-friendly and accessible through the main interface.\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"SPD-1\",\n",
      "            \"modification-type\": \"new\",\n",
      "            \"description\": \"The system shall export bridge inspection results to PowerPoint format within 30 seconds for a report containing up to 100 slides.\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"LAF-1\",\n",
      "            \"modification-type\": \"new\",\n",
      "            \"description\": \"The PowerPoint presentation shall maintain the company's branding guidelines, including logos, color schemes, and fonts.\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"SEC-1\",\n",
      "            \"modification-type\": \"new\",\n",
      "            \"description\": \"The system shall ensure that the exported PowerPoint presentation contains no sensitive information unless the user explicitly includes it.\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n",
      "\n",
      "### Explanation\n",
      "\n",
      "1. **Use Cases:**\n",
      "   - Created a new use case `UC-17` under Data Management focusing on the export functionality to PowerPoint.\n",
      "\n",
      "2. **Functional Requirements:**\n",
      "   - `FR-17.1` ensures the export option is available.\n",
      "   - `FR-17.2` allows inclusion of risk analysis and recommendations.\n",
      "   - `FR-17.3` handles customization options for the export.\n",
      "\n",
      "3. **Non-Functional Requirements:**\n",
      "   - `USA-1` (Usability) ensures the feature is user-friendly.\n",
      "   - `SPD-1` (Speed) sets performance standards for the export process.\n",
      "   - `LAF-1` (Look and Feel) maintains branding in the exported presentation.\n",
      "   - `SEC-1` (Security) ensures no sensitive information is unintentionally included.\n",
      "\n",
      "This approach aligns with the user story objectives and integrates seamlessly into the existing Data Management section of the specification document.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the create and poll SDK helper to create a run and poll the status of\n",
    "# the run until it's in a terminal state.\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id, assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
    "\n",
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "    if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "print(message_content.value)\n",
    "print(\"\\n\".join(citations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11769"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document the inputs into this set of generated requirements\n",
    "import pathlib\n",
    "\n",
    "# Add a placeholder for observations\n",
    "final_output = \"# Observations\\nPlaceholder for developer observations...\\n\\n\"\n",
    "\n",
    "# Capture the list of documents shared for RAG\n",
    "document_input_header = \"# Configuration\"\n",
    "document_list = \"\"\n",
    "for document in RAG_DOCUMENTS:\n",
    "    document_list += f\"{document}\\n\"\n",
    "final_output += f\"{document_input_header}\\n## RAG Files:\\n{document_list}\"\n",
    "final_output += f\"## Model Name\\n{MODEL_NAME}\\n\"\n",
    "final_output += f\"## Prompt{JIRA_ISSUE}\"\n",
    "\n",
    "# Capture the system instructions prompt\n",
    "system_instructions_header = \"# System Instructions\"\n",
    "final_output += f\"\\n{system_instructions_header}\\n{system_instructions}\\n\"\n",
    "\n",
    "# Capture the final output message\n",
    "llm_output_header = \"# Final Output Message\"\n",
    "final_output += f\"\\n{llm_output_header}\\n{message_content.value}\\n\"\n",
    "\n",
    "# Save the final message to a file\n",
    "pathlib.Path(FINAL_OUTPUT_PATH).write_bytes(final_output.encode())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a80b0b954e832a0f0eaa95d53ce03003001ae8d2a35e1423a1be8e7f67fa5ccc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
